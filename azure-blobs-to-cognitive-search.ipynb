{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade numpy openai langchain azure-storage-blob azure-identity unstructured\n",
    "%pip install --index-url=https://pkgs.dev.azure.com/azure-sdk/public/_packaging/azure-sdk-for-python/pypi/simple/ azure-search-documents==11.4.0a20230509004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mac OS: Requires libmagic installation via homebrew\n",
    "# %brew install libmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_embeddings = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading blobs from Azure Storage Account\n",
    "\n",
    "import os\n",
    "\n",
    "from langchain.document_loaders import AzureBlobStorageContainerLoader\n",
    "\n",
    "\n",
    "if generate_embeddings == True:\n",
    "    loader = AzureBlobStorageContainerLoader(\n",
    "        conn_str=os.getenv(\"AZURE_STORAGE_ACCOUNT_CONNECTION_STRING\"),\n",
    "        container=os.getenv(\"AZURE_STORAGE_CONTAINER_NAME\"),\n",
    "    )\n",
    "\n",
    "    # Load and split blobs into chunks\n",
    "    pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert text and embeddings into Azure Cognitive Search\n",
    "\n",
    "from openai.embeddings_utils import get_embedding\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "\n",
    "def embeddings(text):\n",
    "    return get_embedding(text, engine=\"embedding-ada\")\n",
    "\n",
    "\n",
    "# Make sure to create index first:\n",
    "# https://github.com/Azure/cognitive-search-vector-pr/blob/main/docs/rest-api-reference/create-or-update-index.md\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=os.getenv(\"AZURE_SEARCH_ENDPOINT\"),\n",
    "    azure_search_key=os.getenv(\"AZURE_SEARCH_API_KEY\"),\n",
    "    index_name=os.getenv(\"AZURE_SEARCH_INDEX_NAME\"),\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "# Upload documents\n",
    "if generate_embeddings == True:\n",
    "    vector_store.add_documents(documents=pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a similarity search\n",
    "\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_wiki(query):\n",
    "    \"\"\"Search for CWC Wiki data.\"\"\"\n",
    "    docs = vector_store.similarity_search(\n",
    "        query=query,\n",
    "        k=10,\n",
    "        search_type=\"similarity\",\n",
    "    )\n",
    "\n",
    "    return docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an agent\n",
    "\n",
    "from langchain.agents import AgentExecutor, AgentType, load_tools\n",
    "from langchain.agents.loading import AGENT_TO_CLASS\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "# Define system message\n",
    "system_message = \"\"\"You are a friendly AI assistant called Echo. You help answer questions from users about CWC wikipedia.\n",
    "\n",
    "You have access to the following tool:\n",
    "\n",
    "1. search_wiki: useful to search for information about CWC wikipedia. Remember that the search results are in markdown format so you need to parse it.\n",
    "2. llm-math: useful to mathematics calculations.\n",
    "\n",
    "Please always try to use the tools to find answers, do not use any information that isn't coming from the tools.\n",
    "\n",
    "Before using any tool, remember to check the previous messages to see if you can find the answer.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Define format instructions\n",
    "# Workaround #1 for the `Could not parse LLM output` issue:\n",
    "# https://github.com/hwchase17/langchain/issues/1358#issuecomment-1569741405\n",
    "format_instructions = \"\"\"To use a tool, please use the following format:\n",
    "\n",
    "```\n",
    "Thought: Do I need to use a tool? Yes\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "```\n",
    "\n",
    "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the following format(the prefix of \"Thought: \" and \"{ai_prefix}: \" are must be included):\n",
    "\n",
    "```\n",
    "Thought: Do I need to use a tool? No\n",
    "{ai_prefix}: [your response here]\n",
    "```\"\"\"\n",
    "\n",
    "llm = AzureOpenAI(temperature=0, deployment_name=\"testdavinci003\")\n",
    "tools = load_tools([\"llm-math\"], llm=llm) + [search_wiki]\n",
    "chat = AzureChatOpenAI(temperature=0.2, deployment_name=\"gpt-35-turbo\")\n",
    "\n",
    "agent_cls = AGENT_TO_CLASS[AgentType.CONVERSATIONAL_REACT_DESCRIPTION]\n",
    "\n",
    "agent_obj = agent_cls.from_llm_and_tools(\n",
    "    llm=chat,\n",
    "    tools=tools,\n",
    "    prefix=system_message,\n",
    "    format_instructions=format_instructions,\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent_obj,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the CWC Wiki, TPM stands for Technical Program Manager. It is a role within Microsoft's Commercial Software Engineering organization that focuses on leading the coding with customers motion.\n",
      "According to the CWC Wiki, TPMs perform many distinct functions throughout the CSE Execution Lifecycle. They partner with their peers in Development, PMO, and other teams within CSE and Microsoft to effectively perform their role. Additionally, TPMs are ever-learning and are expected to understand the customer, research about industry and market trends, develop technical abilities, and demonstrate thought leadership at various levels.\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "print(agent_executor(\"What does TPM stand for?\")[\"output\"])\n",
    "print(agent_executor(\"What does TPM do?\")[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
