{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai langchain google-api-python-client openai\"[embeddings]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global config\n",
    "generate_embeddings = False\n",
    "agent_verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Combined</th>\n",
       "      <th>Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ordering process,Ordering instructions</td>\n",
       "      <td>How can I order?</td>\n",
       "      <td>You can order easily using our online platform...</td>\n",
       "      <td>Ordering process,Ordering instructions,How can...</td>\n",
       "      <td>[0.0078082336112856865, -0.011418634094297886,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Online ordering benefits,Online ordering discount</td>\n",
       "      <td>Why should I buy online?</td>\n",
       "      <td>Speeding up the process. By ordering online yo...</td>\n",
       "      <td>Online ordering benefits,Online ordering disco...</td>\n",
       "      <td>[0.0011960654519498348, -0.017113571986556053,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Query  \\\n",
       "0             Ordering process,Ordering instructions   \n",
       "1  Online ordering benefits,Online ordering discount   \n",
       "\n",
       "                   Question  \\\n",
       "0          How can I order?   \n",
       "1  Why should I buy online?   \n",
       "\n",
       "                                              Answer  \\\n",
       "0  You can order easily using our online platform...   \n",
       "1  Speeding up the process. By ordering online yo...   \n",
       "\n",
       "                                            Combined  \\\n",
       "0  Ordering process,Ordering instructions,How can...   \n",
       "1  Online ordering benefits,Online ordering disco...   \n",
       "\n",
       "                                           Embedding  \n",
       "0  [0.0078082336112856865, -0.011418634094297886,...  \n",
       "1  [0.0011960654519498348, -0.017113571986556053,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Sample-Faq Embeddings\n",
    "\n",
    "from openai.embeddings_utils import get_embedding\n",
    "import pandas as pd\n",
    "\n",
    "if generate_embeddings:\n",
    "    df = pd.read_csv(\"data/Sample-Faq.csv\", na_filter=False)\n",
    "\n",
    "    df[\"Combined\"] = df.Query.str.strip() + \",\" + df.Question.str.strip()\n",
    "\n",
    "    df[\"Embedding\"] = df.Combined.apply(\n",
    "        lambda x: get_embedding(x, engine=\"embedding-ada\")\n",
    "    )\n",
    "\n",
    "    df.to_csv(\"data/Sample-Faq-Embeddings.csv\", index=False)\n",
    "\n",
    "    df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dataset for products\n",
    "\n",
    "import openai\n",
    "\n",
    "if generate_embeddings:\n",
    "    max_products = 30\n",
    "    prompt = f\"\"\"\n",
    "    Generate a dataset for products with the following requirements:\n",
    "    1. Categories are Toys, Apparel, Electronics, Kitchen appliances and Home decor.\n",
    "    2. Each product should have an ID, Name, Description (200 characters max) and Category.\n",
    "    3. Toys should have an extra range of age group associated with each product info. This is an optional for all other categories.\n",
    "    4. The dataset must have {max_products} products.\n",
    "    5. The product description should be wrapped in double quotes.\n",
    "    6. The dataset must be in CSV format.\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"testdavinci003\",\n",
    "        prompt=prompt,\n",
    "        temperature=1,\n",
    "        max_tokens=1000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None,\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Products Embeddings\n",
    "\n",
    "from openai.embeddings_utils import get_embedding\n",
    "import pandas as pd\n",
    "\n",
    "if generate_embeddings:\n",
    "    df = pd.read_csv(\"data/Products.csv\", na_filter=False)\n",
    "\n",
    "    df[\"Combined\"] = (\n",
    "        df.ID.astype(\"str\")\n",
    "        + \",\"\n",
    "        + df.Name.str.strip()\n",
    "        + \",\"\n",
    "        + df.Description.str.strip()\n",
    "        + \",\"\n",
    "        + df.Category.str.strip()\n",
    "        + \",\"\n",
    "        + df.Age.str.strip()\n",
    "    )\n",
    "\n",
    "    df[\"Embedding\"] = df.Combined.apply(\n",
    "        lambda x: get_embedding(x, engine=\"embedding-ada\")\n",
    "    )\n",
    "\n",
    "    df.to_csv(\"data/Products-Embeddings.csv\", index=False)\n",
    "\n",
    "    df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import redis\n",
    "\n",
    "from redis.commands.search.field import VectorField, TextField\n",
    "from redis.commands.search.indexDefinition import IndexDefinition, IndexType\n",
    "\n",
    "# Redis connection details\n",
    "redis_host = os.getenv(\"REDIS_HOST\")\n",
    "redis_port = os.getenv(\"REDIS_PORT\")\n",
    "redis_password = os.getenv(\"REDIS_PASSWORD\")\n",
    "\n",
    "# Connect to the Redis server\n",
    "conn = redis.Redis(\n",
    "    host=redis_host,\n",
    "    port=redis_port,\n",
    "    password=redis_password,\n",
    "    encoding=\"utf-8\",\n",
    "    decode_responses=True,\n",
    ")\n",
    "\n",
    "p = conn.pipeline(transaction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created faq-index index\n"
     ]
    }
   ],
   "source": [
    "# Store Sample-Faq Embeddings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "\n",
    "def store_faq_embedding(key, question, answer, embedding):\n",
    "    # Convert to numpy array and bytes\n",
    "    vector = np.array(eval(embedding)).astype(np.float32).tobytes()\n",
    "\n",
    "    # Create a new hash with url and embedding\n",
    "    text = f\"{question} {answer}\"\n",
    "    post_hash = {key: text, \"embedding\": vector}\n",
    "\n",
    "    # Create hash\n",
    "    conn.hset(name=f\"{key}:{uuid.uuid1()}\", mapping=post_hash)\n",
    "\n",
    "\n",
    "faq_key = \"faq\"\n",
    "faq_index_name = \"faq-index\"\n",
    "df = pd.read_csv(\"data/Sample-Faq-Embeddings.csv\", na_filter=False)\n",
    "df.apply(\n",
    "    lambda x: store_faq_embedding(faq_key, x.Question, x.Answer, x.Embedding),\n",
    "    axis=1,\n",
    ")\n",
    "p.execute()\n",
    "\n",
    "SCHEMA = [\n",
    "    TextField(faq_key),\n",
    "    VectorField(\n",
    "        \"embedding\",\n",
    "        \"HNSW\",\n",
    "        {\"TYPE\": \"FLOAT32\", \"DIM\": 1536, \"DISTANCE_METRIC\": \"COSINE\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "try:\n",
    "    conn.ft(faq_index_name).create_index(\n",
    "        fields=SCHEMA,\n",
    "        definition=IndexDefinition(prefix=[f\"{faq_key}:\"], index_type=IndexType.HASH),\n",
    "    )\n",
    "\n",
    "    print(f\"Created {faq_index_name} index\")\n",
    "except Exception as e:\n",
    "    print(\"Index already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created product-index index\n"
     ]
    }
   ],
   "source": [
    "# Store Products Embeddings\n",
    "\n",
    "\n",
    "def store_product_embedding(key, id, name, desc, category, age, embedding):\n",
    "    # Convert to numpy array and bytes\n",
    "    vector = np.array(eval(embedding)).astype(np.float32).tobytes()\n",
    "\n",
    "    # Create a new hash with url and embedding\n",
    "    text = f'{id},{name},\"{desc}\",{category},{age}'\n",
    "    post_hash = {key: text, \"embedding\": vector}\n",
    "\n",
    "    # Create hash\n",
    "    conn.hset(name=f\"{key}:{uuid.uuid1()}\", mapping=post_hash)\n",
    "\n",
    "\n",
    "product_key = \"product\"\n",
    "product_index_name = \"product-index\"\n",
    "df = pd.read_csv(\"data/Products-Embeddings.csv\", na_filter=False)\n",
    "df.apply(\n",
    "    lambda x: store_product_embedding(\n",
    "        product_key, x.ID, x.Name, x.Description, x.Category, x.Age, x.Embedding\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "p.execute()\n",
    "\n",
    "SCHEMA = [\n",
    "    TextField(product_key),\n",
    "    VectorField(\n",
    "        \"embedding\",\n",
    "        \"HNSW\",\n",
    "        {\"TYPE\": \"FLOAT32\", \"DIM\": 1536, \"DISTANCE_METRIC\": \"COSINE\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "try:\n",
    "    conn.ft(product_index_name).create_index(\n",
    "        fields=SCHEMA,\n",
    "        definition=IndexDefinition(\n",
    "            prefix=[f\"{product_key}:\"], index_type=IndexType.HASH\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    print(f\"Created {product_index_name} index\")\n",
    "except Exception as e:\n",
    "    print(\"Index already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I can use the `search_product` tool to find recommended toys for a 9-year-old based on their age.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"search_product\",\n",
      "  \"action_input\": \"toys for 9 year olds\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m\n",
      "```csv\n",
      "ID,Name,Description,Category,Suitable Age\n",
      "3,Bicycle,\"A two-wheeled pedal-driven vehicle\",Toys,From 7 to 11\n",
      "4,Train Set,\"A set of miniature trains and tracks\",Toys,From 7 to 11\n",
      "24,Puzzle Game,\"A fun game which requires solving a problem or puzzle\",Toys,From 4 to 7\n",
      "23,Toy Robot,\"A toy version of an artificial humanoid robot\",Toys,From 8 to 11\n",
      "13,Remote Control Car,\"A toy car, which is operated by a TV remote control\",Toys,From 6 to 8\n",
      "14,Lego Set,\"Interlocking pieces of plastic or other material used to build creations\",Toys,From 4 to 7\n",
      "1,Action Figure,\"A figurine of a superhero equipped with weapons and articulation\",Toys,From 6 to 8\n",
      "2,Stuffed Animal,\"A soft toy made from synthetic fabric\",Toys,From 3 to 5\n",
      "9,Toaster,\"A kitchen appliance used to make toast\",Kitchen Appliances,NA\n",
      "28,Game Console,\"A computing device used to play video games\",Electronics,NA\n",
      "\n",
      "```\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the list of toys returned by `search_product`, I can filter the ones that are suitable for 9-year-olds according to the \"Suitable Age\" column of the CSV output.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"search_product\",\n",
      "  \"action_input\": \"toys for 9 year olds\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m\n",
      "```csv\n",
      "ID,Name,Description,Category,Suitable Age\n",
      "3,Bicycle,\"A two-wheeled pedal-driven vehicle\",Toys,From 7 to 11\n",
      "4,Train Set,\"A set of miniature trains and tracks\",Toys,From 7 to 11\n",
      "24,Puzzle Game,\"A fun game which requires solving a problem or puzzle\",Toys,From 4 to 7\n",
      "23,Toy Robot,\"A toy version of an artificial humanoid robot\",Toys,From 8 to 11\n",
      "13,Remote Control Car,\"A toy car, which is operated by a TV remote control\",Toys,From 6 to 8\n",
      "14,Lego Set,\"Interlocking pieces of plastic or other material used to build creations\",Toys,From 4 to 7\n",
      "1,Action Figure,\"A figurine of a superhero equipped with weapons and articulation\",Toys,From 6 to 8\n",
      "2,Stuffed Animal,\"A soft toy made from synthetic fabric\",Toys,From 3 to 5\n",
      "9,Toaster,\"A kitchen appliance used to make toast\",Kitchen Appliances,NA\n",
      "28,Game Console,\"A computing device used to play video games\",Electronics,NA\n",
      "\n",
      "```\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mLooking at the \"Suitable Age\" column of the CSV output, the items from ID 3-4 and ID 23 are the most suitable toys for a 9-year-old.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"search_product\",\n",
      "  \"action_input\": \"bicycle and train set and toy robot for 9 year old\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m\n",
      "```csv\n",
      "ID,Name,Description,Category,Suitable Age\n",
      "3,Bicycle,\"A two-wheeled pedal-driven vehicle\",Toys,From 7 to 11\n",
      "4,Train Set,\"A set of miniature trains and tracks\",Toys,From 7 to 11\n",
      "23,Toy Robot,\"A toy version of an artificial humanoid robot\",Toys,From 8 to 11\n",
      "14,Lego Set,\"Interlocking pieces of plastic or other material used to build creations\",Toys,From 4 to 7\n",
      "13,Remote Control Car,\"A toy car, which is operated by a TV remote control\",Toys,From 6 to 8\n",
      "1,Action Figure,\"A figurine of a superhero equipped with weapons and articulation\",Toys,From 6 to 8\n",
      "24,Puzzle Game,\"A fun game which requires solving a problem or puzzle\",Toys,From 4 to 7\n",
      "2,Stuffed Animal,\"A soft toy made from synthetic fabric\",Toys,From 3 to 5\n",
      "28,Game Console,\"A computing device used to play video games\",Electronics,NA\n",
      "27,Tablet Computer,\"A small computing device with a touchscreen\",Electronics,NA\n",
      "\n",
      "```\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the second `search_product`, I can see that bicycle, train sets, and toy robots are suitable for a 9-year-old. \n",
      "\n",
      "Final Answer: The suitable toys for a 9-year-old are bicycles, train sets, and toy robots.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The suitable toys for a 9-year-old are bicycles, train sets, and toy robots.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Integrate redis search\n",
    "\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.tools import tool\n",
    "\n",
    "from openai.embeddings_utils import get_embedding\n",
    "from redis.commands.search.query import Query\n",
    "\n",
    "\n",
    "def search_vector(index, text_field, text, client, top_k=3):\n",
    "    vector = get_embedding(text, engine=\"embedding-ada\")\n",
    "    query_vector = np.array(vector).astype(np.float32).tobytes()\n",
    "    base_query = f\"*=>[KNN {top_k} @embedding $vector AS vector_score]\"\n",
    "    query = (\n",
    "        Query(base_query)\n",
    "        .return_fields(text_field, \"vector_score\")\n",
    "        .sort_by(\"vector_score\")\n",
    "        .dialect(2)\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        results = client.ft(index).search(query, query_params={\"vector\": query_vector})\n",
    "    except Exception as e:\n",
    "        print(\"Error calling Redis search: \", e)\n",
    "        return None\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_faq(query: str) -> str:\n",
    "    \"\"\"Search for frequently asked questions (FAQ).\"\"\"\n",
    "    results = search_vector(\"faq-index\", \"faq\", query, conn)\n",
    "    faq_results = \"\"\n",
    "    id = 1\n",
    "    for result in results.docs:\n",
    "        faq_results += f\"{id}. {result.faq}\\n\"\n",
    "        id += 1\n",
    "\n",
    "    return faq_results\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_product(query: str) -> str:\n",
    "    \"\"\"Search for products\"\"\"\n",
    "    results = search_vector(\"product-index\", \"product\", query, conn, 30)\n",
    "    product_results = \"\"\n",
    "    for result in results.docs:\n",
    "        product_results += f\"{result.product}\\n\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "```csv\n",
    "ID,Name,Description,Category,Suitable Age\n",
    "{product_results}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "chat = AzureChatOpenAI(temperature=1, deployment_name=\"gpt-35-turbo\")\n",
    "llm = AzureOpenAI(temperature=0, deployment_name=\"testdavinci003\")\n",
    "tools = load_tools([\"llm-math\"], llm=llm) + [search_faq, search_product]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    chat,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=agent_verbose,\n",
    "    # https://github.com/hwchase17/langchain/issues/1358\n",
    "    handle_parsing_errors=\"Check your output and make sure it conforms!\",\n",
    ")\n",
    "\n",
    "agent.run(\n",
    "    \"\"\"\n",
    "You are a friendly AI assistant. When a user is asking for any recommendation about products, always use the age info provided by the tools. Answer the following question.\n",
    "\n",
    "What are suitable toys for a 9 years old?\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Agent\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.loading import AGENT_TO_CLASS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Define system message\n",
    "system_message = \"\"\"You are a friendly AI assistant. You help answer questions from users about our online store that sells many products.\n",
    "\n",
    "You have access to the following tools:\n",
    "\n",
    "1. search_product: useful to search for products.\n",
    "2. search_faq: useful to search for answers about order, payment, delivery, return policy and customer services.\n",
    "3. llm-math: useful to parse CSV format.\n",
    "\n",
    "Please always try to use the tools to find answers, do not use any information that isn't coming from the tools.\n",
    "\n",
    "Before using any tool, remember to check the previous messages to see if you can find the answer.\n",
    "\n",
    "If the user is complaining about our products, follow this process:\n",
    "    1. Ask politely about the issue.\n",
    "    2. Gather details from them about the product such as order id.\n",
    "    3. Try to find out if the complaint is about technical aspects or delivery related.\n",
    "    4. Confirm user that the complaint is registered and referred to relevant department (Technicals / Delivery).\n",
    "    5. Sign off as \"Contoso AI Agent - CAIA\".\n",
    "\n",
    "If the user wants to see what products are available, follow these steps:\n",
    "    1. Use the `search_product` tool to retrieve the list of products and store it in a product_list array.\n",
    "    2. Show the list of products to the user in CSV format.\n",
    "\n",
    "If the user wants to buy a product, search for it in the product_list array and show it to the user for confirmation. If the user has confirmed to buy that product, add it to a cart array.\n",
    "\n",
    "If the user wants to checkout, show all items in the cart array and ask for confirmation. If the user has confirmed to checkout, show the receipt in JSON format.\n",
    "\"\"\"\n",
    "\n",
    "# Define format instructions\n",
    "# Workaround #1 for the `Could not parse LLM output` issue:\n",
    "# https://github.com/hwchase17/langchain/issues/1358#issuecomment-1569741405\n",
    "format_instructions = \"\"\"To use a tool, please use the following format:\n",
    "\n",
    "```\n",
    "Thought: Do I need to use a tool? Yes\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "```\n",
    "\n",
    "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the following format(the prefix of \"Thought: \" and \"{ai_prefix}: \" are must be included):\n",
    "\n",
    "```\n",
    "Thought: Do I need to use a tool? No\n",
    "{ai_prefix}: [your response here]\n",
    "```\"\"\"\n",
    "\n",
    "llm = AzureChatOpenAI(temperature=0.2, deployment_name=\"gpt-35-turbo\")\n",
    "\n",
    "agent_cls = AGENT_TO_CLASS[AgentType.CONVERSATIONAL_REACT_DESCRIPTION]\n",
    "\n",
    "agent_obj = agent_cls.from_llm_and_tools(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prefix=system_message,\n",
    "    format_instructions=format_instructions,\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent_obj,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=agent_verbose,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Panel\n",
    "\n",
    "import panel as pn\n",
    "\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    OutputParserException,\n",
    ")\n",
    "\n",
    "# Panel\n",
    "pn.extension(loading_spinner=\"dots\", loading_color=\"#00aa41\")\n",
    "inp = pn.widgets.TextInput(value=\"\", placeholder=\"Enter text here...\")\n",
    "button_conversation = pn.widgets.Button(name=\"Chat!\")\n",
    "convos = []  # store all panel objects in a list\n",
    "\n",
    "\n",
    "def get_conversations(_):\n",
    "    prompt = inp.value\n",
    "    inp.value = \"\"\n",
    "    if prompt != \"\":\n",
    "        # Workaround #2 for the `Could not parse LLM output` issue.\n",
    "        # Sometimes, the model still doesn't follow our given instructions so we need this\n",
    "        # as a backup solution:\n",
    "        # https://github.com/hwchase17/langchain/issues/1358#issuecomment-1486132587\n",
    "        try:\n",
    "            openai_answer = agent_executor(prompt)[\"output\"]\n",
    "        except OutputParserException as e:\n",
    "            response = str(e)\n",
    "            print(f\"OutputParserException: {response}\")\n",
    "            response = response.removeprefix(\n",
    "                \"Could not parse LLM output: `\"\n",
    "            ).removesuffix(\"`\")\n",
    "            memory.chat_memory.add_message(HumanMessage(content=prompt))\n",
    "            memory.chat_memory.add_message(AIMessage(content=response))\n",
    "            openai_answer = response\n",
    "\n",
    "        convos.append(pn.Row(\"\\U0001F60A\", pn.pane.Markdown(prompt, width=600)))\n",
    "        convos.append(\n",
    "            pn.Row(\n",
    "                \"\\U0001F916\",\n",
    "                pn.pane.Markdown(\n",
    "                    openai_answer, width=600, styles={\"background-color\": \"#F6F6F6\"}\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return pn.Column(*convos)\n",
    "\n",
    "\n",
    "interactive_conversation = pn.bind(get_conversations, button_conversation)\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    inp,\n",
    "    pn.Row(button_conversation),\n",
    "    pn.panel(interactive_conversation, loading_indicator=True, height=500),\n",
    ")\n",
    "\n",
    "dashboard.servable()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
